{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_excel(\"3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop column: 'L1_BloodGroup_First'\n",
    "df = df.drop(columns=['L1_BloodGroup_First'])\n",
    "# Drop rows with missing data in column: 'Outcome_InhospitalMortality'\n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting internal and external validation\n",
    "\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig features and target variables\n",
    "\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig features and target variables for extrenal validation dataset\n",
    "\n",
    "X_ex = df_external_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_ex  = df_external_validation['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y, test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicating numerical variables\n",
    "\n",
    "num =  [\n",
    "    \"symtpm_to_referral\",\n",
    "    \"VS_O2satwithoutsupp\",\n",
    "    \"VS_PR\",\n",
    "    \"VS_diastolic BP\",\n",
    "    \"VS_Systolic BP\",\n",
    "    \"VS_RR\",\n",
    "    \"VS_T\",\n",
    "    \"LAB_WBC_1\",\n",
    "    \"LAB_LYMPHH_1\",\n",
    "    \"LAB_NEUT_1\",\n",
    "    \"LAB_PLT_1\",\n",
    "    \"LAB_HB_1\",\n",
    "    \"LAB_MCV_1\",\n",
    "    \"LAB_CR_1\",\n",
    "    \"LAB_NA_First\",\n",
    "    \"LAB_K_First\",\n",
    "    \"LAB_ALKP_First\",\n",
    "    \"LAB_ESR_First\",\n",
    "    \"LAB_CPK_First\",\n",
    "    \"LAB_PTT_First\",\n",
    "    \"LAB_PT_First\",\n",
    "    \"LAB_INR_First\",\n",
    "    \"Demographic_Age\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicationg categorical variables\n",
    "\n",
    "cat = X.drop(columns= num).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputing categorical data with knn imputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X_train_cat = imputer.fit_transform(np.array(X_train[cat]))\n",
    "X_test_cat = imputer.fit_transform(np.array(X_test[cat]))\n",
    "X_ex_cat = imputer.fit_transform(np.array(X_ex[cat]))\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=cat)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=cat)\n",
    "X_ex_cat = pd.DataFrame(X_ex_cat, columns=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# imputing numerical data with terative imputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=50, random_state=0)\n",
    "\n",
    "X_train_num = imputer.fit_transform(X_train[num])\n",
    "X_test_num = imputer.fit_transform(X_test[num])\n",
    "X_ex_num = imputer.fit_transform(X_ex[num])\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=num)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=num)\n",
    "X_ex_num = pd.DataFrame(X_ex_num, columns=num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging categorical and numerical data\n",
    "\n",
    "X_train = pd.concat([X_train_cat, X_train_num], axis=1)\n",
    "X_test = pd.concat([X_test_cat, X_test_num], axis=1)\n",
    "X_ex = pd.concat([X_ex_cat, X_ex_num], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# handing skewness in the dataset \n",
    "\n",
    "from operator import itemgetter\n",
    "def find_skewness(train, num):\n",
    "    \"\"\"\n",
    "    Calculate the skewness of the columns and segregate the positive\n",
    "    and negative skewed data.\n",
    "    \"\"\"\n",
    "    skew_dict = {}\n",
    "    for col in num:\n",
    "        skew_dict[col] = train[col].skew()\n",
    "    skew_dict = dict(sorted(skew_dict.items(),key=itemgetter(1)))\n",
    "    positive_skew_dict = {k:v for (k,v) in skew_dict.items() if v>0}\n",
    "    negative_skew_dict = {k:v for (k,v) in skew_dict.items() if v<0}\n",
    "    return skew_dict, positive_skew_dict, negative_skew_dict\n",
    "def add_constant(data, highly_pos_skewed):\n",
    "    \"\"\"\n",
    "    Look for zeros in the columns. If zeros are present then the log(0) would result in -infinity.\n",
    "    So before transforming it we need to add it with some constant.\n",
    "    \"\"\"\n",
    "    C = 1\n",
    "    for col in highly_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            if(len(data[data[col] == 0]) > 0):\n",
    "                data[col] = data[col] + C\n",
    "    return data\n",
    "def log_transform(data, highly_pos_skewed):\n",
    "    \"\"\"\n",
    "    Log transformation of highly positively skewed columns.\n",
    "    \"\"\"\n",
    "    for col in highly_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            data[col] = np.log10(data[col])\n",
    "    return data\n",
    "def sqrt_transform(data, moderately_pos_skewed):\n",
    "    \"\"\"\n",
    "    Square root transformation of moderately skewed columns.\n",
    "    \"\"\"\n",
    "    for col in moderately_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            data[col] = np.sqrt(data[col])\n",
    "    return data\n",
    "def reflect_sqrt_transform(data, moderately_neg_skewed):\n",
    "    \"\"\"\n",
    "    Reflection and log transformation of highly negatively skewed \n",
    "    columns.\n",
    "    \"\"\"\n",
    "    for col in moderately_neg_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            K = max(data[col]) + 1\n",
    "            data[col] = np.sqrt(K - data[col])\n",
    "    return data\n",
    "\"\"\"\n",
    "If skewness is less than -1 or greater than 1, the distribution is highly skewed.\n",
    "If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n",
    "If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\"\"\"\n",
    "skew_dict, positive_skew_dict, negative_skew_dict = find_skewness(X_train, num)\n",
    "moderately_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>0.5 and v<=1}\n",
    "highly_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>1}\n",
    "moderately_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v>-1 and v<=0.5}\n",
    "highly_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v<-1}\n",
    "'''Transform train data.'''\n",
    "X_train = add_constant(X_train, highly_pos_skewed)\n",
    "X_train = log_transform(X_train, highly_pos_skewed)\n",
    "X_train = sqrt_transform(X_train, moderately_pos_skewed)\n",
    "X_train = reflect_sqrt_transform(X_train, moderately_neg_skewed )\n",
    "'''Transform test data.'''\n",
    "X_test = add_constant(X_test, highly_pos_skewed)\n",
    "X_test = log_transform(X_test, highly_pos_skewed)\n",
    "X_test = sqrt_transform(X_test, moderately_pos_skewed)\n",
    "X_test = reflect_sqrt_transform(X_test, moderately_neg_skewed )\n",
    "\n",
    "X_ex = add_constant(X_ex, highly_pos_skewed)\n",
    "X_ex = log_transform(X_ex, highly_pos_skewed)\n",
    "X_ex = sqrt_transform(X_ex, moderately_pos_skewed)\n",
    "X_ex = reflect_sqrt_transform(X_ex, moderately_neg_skewed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handilng skewness can make some null values.\n",
    "# here we handle these missing values\n",
    "\n",
    "def clean_data(X_train):\n",
    "    # Replace missing values with the mean of each column in: 'L1_BloodGroup_First', 'Demographic_Gender' and 74 other columns\n",
    "    X_train = X_train.fillna({ 'Demographic_Gender': X_train['Demographic_Gender'].mean(), 'Symptom_Caugh': X_train['Symptom_Caugh'].mean(), 'Symptom_Dyspnea': X_train['Symptom_Dyspnea'].mean(), 'Symptom_Fever': X_train['Symptom_Fever'].mean(), 'Symptom_Chiver': X_train['Symptom_Chiver'].mean(), 'Symptom_Mylagia': X_train['Symptom_Mylagia'].mean(), 'Symptom_Weakness': X_train['Symptom_Weakness'].mean(), 'Symptom_LOC': X_train['Symptom_LOC'].mean(), 'Symptom_Sore through': X_train['Symptom_Sore through'].mean(), 'Symptom_Rhinorrhea': X_train['Symptom_Rhinorrhea'].mean(), 'Symptom_Smelling disorder': X_train['Symptom_Smelling disorder'].mean(), 'Symptom_nauseaVomit': X_train['Symptom_nauseaVomit'].mean(), 'Symptom_Anorexia': X_train['Symptom_Anorexia'].mean(), 'Symptom_Diarhhea': X_train['Symptom_Diarhhea'].mean(), 'Symptom_ChestPain': X_train['Symptom_ChestPain'].mean(), 'Symptom_Seizure': X_train['Symptom_Seizure'].mean(), 'Symptom_SkinLesion': X_train['Symptom_SkinLesion'].mean(), 'Symptom_Jointpain': X_train['Symptom_Jointpain'].mean(), 'Symptom_Headache': X_train['Symptom_Headache'].mean(), 'Symptom_AbdominalPain': X_train['Symptom_AbdominalPain'].mean(), 'Symptom_Earpain': X_train['Symptom_Earpain'].mean(), 'Symptom_Hemorrhasia': X_train['Symptom_Hemorrhasia'].mean(), 'Symptom_Hemiparesia': X_train['Symptom_Hemiparesia'].mean(), 'MH_PregnanAcy': X_train['MH_PregnanAcy'].mean(), 'MH_CurremtSmoker': X_train['MH_CurremtSmoker'].mean(), 'MH_Alcoholuser': X_train['MH_Alcoholuser'].mean(), 'MH_Opiumuser': X_train['MH_Opiumuser'].mean(), 'MH_Hookahuser': X_train['MH_Hookahuser'].mean(), 'MH_HTN': X_train['MH_HTN'].mean(), 'MH_IHD': X_train['MH_IHD'].mean(), 'MH_CABG': X_train['MH_CABG'].mean(), 'MH_CHF': X_train['MH_CHF'].mean(), 'MH_Ashtma': X_train['MH_Ashtma'].mean(), 'MH_COPD': X_train['MH_COPD'].mean(), 'MH_DM': X_train['MH_DM'].mean(), 'MH_Pneumonia': X_train['MH_Pneumonia'].mean(), 'MH_CVA': X_train['MH_CVA'].mean(), 'MH_GIdisorder': X_train['MH_GIdisorder'].mean(), 'MH_CKD': X_train['MH_CKD'].mean(), 'MH_RA': X_train['MH_RA'].mean(), 'Cancer': X_train['Cancer'].mean(), 'MH_HLP': X_train['MH_HLP'].mean(), 'MH_Hep C': X_train['MH_Hep C'].mean(), 'MH_Thyroid dysfunction': X_train['MH_Thyroid dysfunction'].mean(), 'MH_Immunocompromised': X_train['MH_Immunocompromised'].mean(), 'MH_ChronicSeizure': X_train['MH_ChronicSeizure'].mean(), 'MH_TB': X_train['MH_TB'].mean(), 'MH_Anemia': X_train['MH_Anemia'].mean(), 'MH_Fattyliver': X_train['MH_Fattyliver'].mean(), 'MH_Psychologicaldisorder': X_train['MH_Psychologicaldisorder'].mean(), 'MH_Parkinson': X_train['MH_Parkinson'].mean(), 'MH_Alzhimer': X_train['MH_Alzhimer'].mean(), 'symtpm_to_referral': X_train['symtpm_to_referral'].mean(), 'VS_O2satwithoutsupp': X_train['VS_O2satwithoutsupp'].mean(), 'VS_PR': X_train['VS_PR'].mean(), 'VS_diastolic BP': X_train['VS_diastolic BP'].mean(), 'VS_Systolic BP': X_train['VS_Systolic BP'].mean(), 'VS_RR': X_train['VS_RR'].mean(), 'VS_T': X_train['VS_T'].mean(), 'LAB_WBC_1': X_train['LAB_WBC_1'].mean(), 'LAB_LYMPHH_1': X_train['LAB_LYMPHH_1'].mean(), 'LAB_NEUT_1': X_train['LAB_NEUT_1'].mean(), 'LAB_PLT_1': X_train['LAB_PLT_1'].mean(), 'LAB_HB_1': X_train['LAB_HB_1'].mean(), 'LAB_MCV_1': X_train['LAB_MCV_1'].mean(), 'LAB_CR_1': X_train['LAB_CR_1'].mean(), 'LAB_NA_First': X_train['LAB_NA_First'].mean(), 'LAB_K_First': X_train['LAB_K_First'].mean(), 'LAB_ALKP_First': X_train['LAB_ALKP_First'].mean(), 'LAB_ESR_First': X_train['LAB_ESR_First'].mean(), 'LAB_CPK_First': X_train['LAB_CPK_First'].mean(), 'LAB_PTT_First': X_train['LAB_PTT_First'].mean(), 'LAB_PT_First': X_train['LAB_PT_First'].mean(), 'LAB_INR_First': X_train['LAB_INR_First'].mean(), 'Demographic_Age': X_train['Demographic_Age'].mean()})\n",
    "    return X_train\n",
    "\n",
    "X_train = clean_data(X_train.copy())\n",
    "X_test = clean_data(X_test.copy())\n",
    "X_ex = clean_data(X_ex.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# define the function to standard numerca data\n",
    "\n",
    "transform = StandardScaler()\n",
    "\n",
    "def standard(f):\n",
    "    df_ex_normalize = transform.fit_transform(f)\n",
    "    df_ex_normalize = pd.DataFrame(df_ex_normalize)\n",
    "    df_ex_normalize.columns = f.columns\n",
    "    return df_ex_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standarding nmerical data with StandardScaler\n",
    "\n",
    "num = list(X_train.columns[X_train.columns.get_loc('VS_O2satwithoutsupp'): X_train.columns.get_loc('Demographic_Age') + 1]\n",
    ")\n",
    "\n",
    "X_train[num]=standard(X_train[num])\n",
    "X_test[num]=standard(X_test[num])\n",
    "X_ex[num]=standard(X_ex[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# we tried different undersampling and oversampling techniques. SMOTE performed better than others.\n",
    "\n",
    "over_sampler = SMOTE()\n",
    "X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "X_test, y_test = over_sampler.fit_resample(X_test, y_test)\n",
    "X_ex, y_ex = over_sampler.fit_resample(X_ex, y_ex )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#function that selects most important features using lasso\n",
    "\n",
    "def lasso_feature_selector(X_train, y_train,X_test , X_ex):\n",
    "\n",
    "    \n",
    "    lasso = Lasso(alpha=0.001,random_state=42 )\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    absolute_coeffs = np.abs(lasso.coef_)\n",
    "    sorted_indices = np.argsort(absolute_coeffs)[::-1]\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_ex = pd.DataFrame(X_ex)\n",
    "\n",
    "    selected_feature_indices = sorted_indices[:40]\n",
    "    selected_feature_indices = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "\n",
    "    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\n",
    "    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\n",
    "    X_ex = X_ex.iloc[:, selected_feature_indices]\n",
    "    return X_train_selected_Mortality_ICU ,X_test_selected_Mortality_ICU,X_ex, selected_feature_indices\n",
    "\n",
    "X_train,X_test,X_ex, selected_feature_indices = lasso_feature_selector(X_train, y_train,X_test,X_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# metrics caculator function \n",
    "\n",
    "def calculate_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    \n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "\n",
    "def calculate_and_update_model_metrics(y_test, y_predicted,y_ex, y_ex_predicted):\n",
    "    accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_predicted)\n",
    "    model = {}\n",
    "    model[\"accuracy\"] = accuracy\n",
    "    model[\"precision\"] = precision\n",
    "    model[\"recall\"] = recall\n",
    "    model[\"specificity\"] = specificity\n",
    "    model[\"f1\"] = f1\n",
    "    model[\"AUC\"] = roc_auc_score(y_test, y_predicted)\n",
    "    \n",
    "    accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex = calculate_metrics(y_ex, y_ex_predicted)\n",
    "    model[\"accuracy_ex\"] = accuracy_ex\n",
    "    model[\"precision_ex\"] = precision_ex\n",
    "    model[\"recall_ex\"] = recall_ex\n",
    "    model[\"specificity_ex\"] = specificity_ex\n",
    "    model[\"f1_ex\"] = f1_ex\n",
    "    model[\"AUC_ex\"] = roc_auc_score(y_ex, y_ex_predicted)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(X_train, y_train, X_test, y_test, X_ex, y_ex):\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    "    # Predictions and probabilities for test set\n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Predictions and probabilities for external set\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    model_metrics = calculate_and_update_model_metrics(y_test, y_pred_test, y_ex, y_pred_external)\n",
    "\n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "\n",
    "    return model_metrics, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42], 'probability': [True]}\n",
    "    lr = svm.SVC(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_tree(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {}\n",
    "    lr = KNeighborsClassifier()\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_forest(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = RandomForestClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def train_and_evaluate_boost(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = XGBClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =   calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_neural = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50)],  # You can adjust the architecture here\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [200],\n",
    "        'random_state': [42],\n",
    "        'early_stopping': [True],\n",
    "        'validation_fraction': [0.1],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "\n",
    "\n",
    "    neural = MLPClassifier(random_state=42)\n",
    "\n",
    "    grid_search_neural = GridSearchCV(\n",
    "        estimator=neural,\n",
    "        param_grid=parameters_neural,\n",
    "        cv=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    neural_cv = grid_search_neural.fit(X_train, y_train)\n",
    "\n",
    "   \n",
    "    best_classifier_lr = neural_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =   calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_neural = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50)],  # You can adjust the architecture here\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [200],\n",
    "        'random_state': [42],\n",
    "        'early_stopping': [True],\n",
    "        'validation_fraction': [0.1],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "\n",
    "\n",
    "    lr = MLPClassifier(random_state=42)\n",
    "\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_neural,\n",
    "        #cv=5\n",
    "    )\n",
    "    \n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function that shows the results of all models in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_train, y_train, X_test, y_test, X_ex, y_ex):\n",
    "    list_Outcome_InhospitalMortality=[]\n",
    "    y_train_ = np.array(y_train)\n",
    "    y_test_ = np.array(y_test)\n",
    "\n",
    "    y_ex_ = np.array(y_ex)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    list_Outcome_InhospitalMortality.extend([logistic_regression_classifier(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                                train_and_evaluate_svm(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_tree(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_knn(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_forest(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_boost(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_neural(X_train, y_train, X_test, y_test, X_ex, y_ex)])\n",
    "\n",
    "\n",
    "    result_dic_list_Outcome_InhospitalMortality = dict(zip(['logistic regression', 'SVM', 'Decision tree', 'knn', 'Random forest', 'XGboost', 'neural net'], list_Outcome_InhospitalMortality))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    merged_dict = {}\n",
    "\n",
    "    # List of dictionary names and their corresponding dictionaries\n",
    "    dict_list = [('Outcome_InhospitalMortality', result_dic_list_Outcome_InhospitalMortality)]\n",
    "\n",
    "    # Merge the dictionaries\n",
    "    for name, result_dict in dict_list:\n",
    "        merged_dict[name] = result_dict\n",
    "\n",
    "    # The merged_dict now contains all the dictionaries merged together\n",
    "\n",
    "\n",
    "    dff = pd.DataFrame(merged_dict)\n",
    "\n",
    "\n",
    "    dff = dff.transpose()\n",
    "\n",
    "\n",
    "    dff.reset_index(inplace=True)\n",
    "    dff.rename(columns={'index': 'Method'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for outcome, models in merged_dict.items():\n",
    "        for model, metrics in models.items():\n",
    "            accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex = metrics[0]['accuracy'], metrics[0]['precision'], metrics[0]['recall'], metrics[0]['specificity'], metrics[0]['f1'], metrics[0]['AUC'],metrics[0]['accuracy_ex'], metrics[0]['precision_ex'], metrics[0]['recall_ex'], metrics[0]['specificity_ex'], metrics[0]['f1_ex'], metrics[0]['AUC_ex']\n",
    "            y_true, y_predicted,y_true_ex,y_predicted_ex , y_pred_proba_test , y_pred_proba_external = metrics[1]['y_true'], metrics[1]['y_predicted'],metrics[1]['y_true_ex'], metrics[1]['y_predicted_ex'], metrics[1]['y_pred_proba_test'], metrics[1]['y_pred_proba_external']\n",
    "            data.append([outcome, model,accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex, y_true.tolist(), y_predicted.tolist(),y_true_ex.tolist(),y_predicted_ex.tolist(),y_pred_proba_test.tolist(),y_pred_proba_external.tolist()])\n",
    "\n",
    "    columns = ['Outcome', 'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1','AUC', 'Accuracy_ex', 'Precision_ex', 'Recall_ex', 'Specificity_ex', 'F1_ex','AUC_ex', 'y_true', 'y_predicted', 'y_true_ex', 'y_predicted_ex' , 'y_pred_proba_test', 'y_pred_proba_external']\n",
    "\n",
    "    dff = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return dff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the result's table\n",
    "\n",
    "d = run_all_models(X_train, y_train, X_test, y_test, X_ex, y_ex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.to_csv('CML_prob.csv',index=False)\n",
    "d.to_excel('CML_prob.xlsx',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
