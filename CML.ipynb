{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_excel(\"3.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop column: 'L1_BloodGroup_First'\n",
    "df = df.drop(columns=['L1_BloodGroup_First'])\n",
    "# Drop rows with missing data in column: 'Outcome_InhospitalMortality'\n",
    "df = df.dropna(subset=['Outcome_InhospitalMortality'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting internal and external validation\n",
    "\n",
    "df_internal_validation = df[df['Patient_Hospital']!=\"Hospital2\"]\n",
    "df_external_validation = df[df['Patient_Hospital']==\"Hospital2\"]\n",
    "df_internal_validation = df_internal_validation.drop(columns=['Patient_Hospital'])\n",
    "df_external_validation = df_external_validation.drop(columns=['Patient_Hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig features and target variables\n",
    "\n",
    "X = df_internal_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y  = df_internal_validation['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig features and target variables for extrenal validation dataset\n",
    "\n",
    "X_ex = df_external_validation.drop(columns=['Outcome_InhospitalMortality', 'TM_S_Intubation', 'Outcome_ICUadmission','TM_S_Dialysis'])\n",
    "y_ex  = df_external_validation['Outcome_InhospitalMortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X[:400],y[:400], test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicating numerical variables\n",
    "\n",
    "num =  [\n",
    "    \"symtpm_to_referral\",\n",
    "    \"VS_O2satwithoutsupp\",\n",
    "    \"VS_PR\",\n",
    "    \"VS_diastolic BP\",\n",
    "    \"VS_Systolic BP\",\n",
    "    \"VS_RR\",\n",
    "    \"VS_T\",\n",
    "    \"LAB_WBC_1\",\n",
    "    \"LAB_LYMPHH_1\",\n",
    "    \"LAB_NEUT_1\",\n",
    "    \"LAB_PLT_1\",\n",
    "    \"LAB_HB_1\",\n",
    "    \"LAB_MCV_1\",\n",
    "    \"LAB_CR_1\",\n",
    "    \"LAB_NA_First\",\n",
    "    \"LAB_K_First\",\n",
    "    \"LAB_ALKP_First\",\n",
    "    \"LAB_ESR_First\",\n",
    "    \"LAB_CPK_First\",\n",
    "    \"LAB_PTT_First\",\n",
    "    \"LAB_PT_First\",\n",
    "    \"LAB_INR_First\",\n",
    "    \"Demographic_Age\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicationg categorical variables\n",
    "\n",
    "cat = X.drop(columns= num).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# imputing categorical data with knn imputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "X_train_cat = imputer.fit_transform(np.array(X_train[cat]))\n",
    "X_test_cat = imputer.fit_transform(np.array(X_test[cat]))\n",
    "X_ex_cat = imputer.fit_transform(np.array(X_ex[cat]))\n",
    "\n",
    "X_train_cat = pd.DataFrame(X_train_cat, columns=cat)\n",
    "X_test_cat = pd.DataFrame(X_test_cat, columns=cat)\n",
    "X_ex_cat = pd.DataFrame(X_ex_cat, columns=cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# imputing numerical data with terative imputer\n",
    "\n",
    "imputer = IterativeImputer(max_iter=50, random_state=0)\n",
    "\n",
    "X_train_num = imputer.fit_transform(X_train[num])\n",
    "X_test_num = imputer.fit_transform(X_test[num])\n",
    "X_ex_num = imputer.fit_transform(X_ex[num])\n",
    "\n",
    "X_train_num = pd.DataFrame(X_train_num, columns=num)\n",
    "X_test_num = pd.DataFrame(X_test_num, columns=num)\n",
    "X_ex_num = pd.DataFrame(X_ex_num, columns=num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging categorical and numerical data\n",
    "\n",
    "X_train = pd.concat([X_train_cat, X_train_num], axis=1)\n",
    "X_test = pd.concat([X_test_cat, X_test_num], axis=1)\n",
    "X_ex = pd.concat([X_ex_cat, X_ex_num], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'\\'# handing skewness in the dataset \\n\\nfrom operator import itemgetter\\ndef find_skewness(train, num):\\n    \"\"\"\\n    Calculate the skewness of the columns and segregate the positive\\n    and negative skewed data.\\n    \"\"\"\\n    skew_dict = {}\\n    for col in num:\\n        skew_dict[col] = train[col].skew()\\n    skew_dict = dict(sorted(skew_dict.items(),key=itemgetter(1)))\\n    positive_skew_dict = {k:v for (k,v) in skew_dict.items() if v>0}\\n    negative_skew_dict = {k:v for (k,v) in skew_dict.items() if v<0}\\n    return skew_dict, positive_skew_dict, negative_skew_dict\\ndef add_constant(data, highly_pos_skewed):\\n    \"\"\"\\n    Look for zeros in the columns. If zeros are present then the log(0) would result in -infinity.\\n    So before transforming it we need to add it with some constant.\\n    \"\"\"\\n    C = 1\\n    for col in highly_pos_skewed.keys():\\n        if(col != \\'SalePrice\\'):\\n            if(len(data[data[col] == 0]) > 0):\\n                data[col] = data[col] + C\\n    return data\\ndef log_transform(data, highly_pos_skewed):\\n    \"\"\"\\n    Log transformation of highly positively skewed columns.\\n    \"\"\"\\n    for col in highly_pos_skewed.keys():\\n        if(col != \\'SalePrice\\'):\\n            data[col] = np.log10(data[col])\\n    return data\\ndef sqrt_transform(data, moderately_pos_skewed):\\n    \"\"\"\\n    Square root transformation of moderately skewed columns.\\n    \"\"\"\\n    for col in moderately_pos_skewed.keys():\\n        if(col != \\'SalePrice\\'):\\n            data[col] = np.sqrt(data[col])\\n    return data\\ndef reflect_sqrt_transform(data, moderately_neg_skewed):\\n    \"\"\"\\n    Reflection and log transformation of highly negatively skewed \\n    columns.\\n    \"\"\"\\n    for col in moderately_neg_skewed.keys():\\n        if(col != \\'SalePrice\\'):\\n            K = max(data[col]) + 1\\n            data[col] = np.sqrt(K - data[col])\\n    return data\\n\"\"\"\\nIf skewness is less than -1 or greater than 1, the distribution is highly skewed.\\nIf skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\\nIf skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\\n\"\"\"\\nskew_dict, positive_skew_dict, negative_skew_dict = find_skewness(X_train, num)\\nmoderately_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>0.5 and v<=1}\\nhighly_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>1}\\nmoderately_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v>-1 and v<=0.5}\\nhighly_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v<-1}\\n\\'\\'Transform train data.\\'\\'\\nX_train = add_constant(X_train, highly_pos_skewed)\\nX_train = log_transform(X_train, highly_pos_skewed)\\nX_train = sqrt_transform(X_train, moderately_pos_skewed)\\nX_train = reflect_sqrt_transform(X_train, moderately_neg_skewed )\\n\\'\\'Transform test data.\\'\\'\\nX_test = add_constant(X_test, highly_pos_skewed)\\nX_test = log_transform(X_test, highly_pos_skewed)\\nX_test = sqrt_transform(X_test, moderately_pos_skewed)\\nX_test = reflect_sqrt_transform(X_test, moderately_neg_skewed )\\n\\nX_ex = add_constant(X_ex, highly_pos_skewed)\\nX_ex = log_transform(X_ex, highly_pos_skewed)\\nX_ex = sqrt_transform(X_ex, moderately_pos_skewed)\\nX_ex = reflect_sqrt_transform(X_ex, moderately_neg_skewed )'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handing skewness in the dataset \n",
    "\n",
    "from operator import itemgetter\n",
    "def find_skewness(train, num):\n",
    "    \"\"\"\n",
    "    Calculate the skewness of the columns and segregate the positive\n",
    "    and negative skewed data.\n",
    "    \"\"\"\n",
    "    skew_dict = {}\n",
    "    for col in num:\n",
    "        skew_dict[col] = train[col].skew()\n",
    "    skew_dict = dict(sorted(skew_dict.items(),key=itemgetter(1)))\n",
    "    positive_skew_dict = {k:v for (k,v) in skew_dict.items() if v>0}\n",
    "    negative_skew_dict = {k:v for (k,v) in skew_dict.items() if v<0}\n",
    "    return skew_dict, positive_skew_dict, negative_skew_dict\n",
    "def add_constant(data, highly_pos_skewed):\n",
    "    \"\"\"\n",
    "    Look for zeros in the columns. If zeros are present then the log(0) would result in -infinity.\n",
    "    So before transforming it we need to add it with some constant.\n",
    "    \"\"\"\n",
    "    C = 1\n",
    "    for col in highly_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            if(len(data[data[col] == 0]) > 0):\n",
    "                data[col] = data[col] + C\n",
    "    return data\n",
    "def log_transform(data, highly_pos_skewed):\n",
    "    \"\"\"\n",
    "    Log transformation of highly positively skewed columns.\n",
    "    \"\"\"\n",
    "    for col in highly_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            data[col] = np.log10(data[col])\n",
    "    return data\n",
    "def sqrt_transform(data, moderately_pos_skewed):\n",
    "    \"\"\"\n",
    "    Square root transformation of moderately skewed columns.\n",
    "    \"\"\"\n",
    "    for col in moderately_pos_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            data[col] = np.sqrt(data[col])\n",
    "    return data\n",
    "def reflect_sqrt_transform(data, moderately_neg_skewed):\n",
    "    \"\"\"\n",
    "    Reflection and log transformation of highly negatively skewed \n",
    "    columns.\n",
    "    \"\"\"\n",
    "    for col in moderately_neg_skewed.keys():\n",
    "        if(col != 'SalePrice'):\n",
    "            K = max(data[col]) + 1\n",
    "            data[col] = np.sqrt(K - data[col])\n",
    "    return data\n",
    "\"\"\"\n",
    "If skewness is less than -1 or greater than 1, the distribution is highly skewed.\n",
    "If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.\n",
    "If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.\n",
    "\"\"\"\n",
    "skew_dict, positive_skew_dict, negative_skew_dict = find_skewness(X_train, num)\n",
    "moderately_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>0.5 and v<=1}\n",
    "highly_pos_skewed = {k:v for (k,v) in positive_skew_dict.items() if v>1}\n",
    "moderately_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v>-1 and v<=0.5}\n",
    "highly_neg_skewed = {k:v for (k,v) in negative_skew_dict.items() if v<-1}\n",
    "'''Transform train data.'''\n",
    "X_train = add_constant(X_train, highly_pos_skewed)\n",
    "X_train = log_transform(X_train, highly_pos_skewed)\n",
    "X_train = sqrt_transform(X_train, moderately_pos_skewed)\n",
    "X_train = reflect_sqrt_transform(X_train, moderately_neg_skewed )\n",
    "'''Transform test data.'''\n",
    "X_test = add_constant(X_test, highly_pos_skewed)\n",
    "X_test = log_transform(X_test, highly_pos_skewed)\n",
    "X_test = sqrt_transform(X_test, moderately_pos_skewed)\n",
    "X_test = reflect_sqrt_transform(X_test, moderately_neg_skewed )\n",
    "\n",
    "X_ex = add_constant(X_ex, highly_pos_skewed)\n",
    "X_ex = log_transform(X_ex, highly_pos_skewed)\n",
    "X_ex = sqrt_transform(X_ex, moderately_pos_skewed)\n",
    "X_ex = reflect_sqrt_transform(X_ex, moderately_neg_skewed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handilng skewness can make some null values.\n",
    "# here we handle these missing values\n",
    "\n",
    "def clean_data(X_train):\n",
    "    # Replace missing values with the mean of each column in: 'L1_BloodGroup_First', 'Demographic_Gender' and 74 other columns\n",
    "    X_train = X_train.fillna({ 'Demographic_Gender': X_train['Demographic_Gender'].mean(), 'Symptom_Caugh': X_train['Symptom_Caugh'].mean(), 'Symptom_Dyspnea': X_train['Symptom_Dyspnea'].mean(), 'Symptom_Fever': X_train['Symptom_Fever'].mean(), 'Symptom_Chiver': X_train['Symptom_Chiver'].mean(), 'Symptom_Mylagia': X_train['Symptom_Mylagia'].mean(), 'Symptom_Weakness': X_train['Symptom_Weakness'].mean(), 'Symptom_LOC': X_train['Symptom_LOC'].mean(), 'Symptom_Sore through': X_train['Symptom_Sore through'].mean(), 'Symptom_Rhinorrhea': X_train['Symptom_Rhinorrhea'].mean(), 'Symptom_Smelling disorder': X_train['Symptom_Smelling disorder'].mean(), 'Symptom_nauseaVomit': X_train['Symptom_nauseaVomit'].mean(), 'Symptom_Anorexia': X_train['Symptom_Anorexia'].mean(), 'Symptom_Diarhhea': X_train['Symptom_Diarhhea'].mean(), 'Symptom_ChestPain': X_train['Symptom_ChestPain'].mean(), 'Symptom_Seizure': X_train['Symptom_Seizure'].mean(), 'Symptom_SkinLesion': X_train['Symptom_SkinLesion'].mean(), 'Symptom_Jointpain': X_train['Symptom_Jointpain'].mean(), 'Symptom_Headache': X_train['Symptom_Headache'].mean(), 'Symptom_AbdominalPain': X_train['Symptom_AbdominalPain'].mean(), 'Symptom_Earpain': X_train['Symptom_Earpain'].mean(), 'Symptom_Hemorrhasia': X_train['Symptom_Hemorrhasia'].mean(), 'Symptom_Hemiparesia': X_train['Symptom_Hemiparesia'].mean(), 'MH_PregnanAcy': X_train['MH_PregnanAcy'].mean(), 'MH_CurremtSmoker': X_train['MH_CurremtSmoker'].mean(), 'MH_Alcoholuser': X_train['MH_Alcoholuser'].mean(), 'MH_Opiumuser': X_train['MH_Opiumuser'].mean(), 'MH_Hookahuser': X_train['MH_Hookahuser'].mean(), 'MH_HTN': X_train['MH_HTN'].mean(), 'MH_IHD': X_train['MH_IHD'].mean(), 'MH_CABG': X_train['MH_CABG'].mean(), 'MH_CHF': X_train['MH_CHF'].mean(), 'MH_Ashtma': X_train['MH_Ashtma'].mean(), 'MH_COPD': X_train['MH_COPD'].mean(), 'MH_DM': X_train['MH_DM'].mean(), 'MH_Pneumonia': X_train['MH_Pneumonia'].mean(), 'MH_CVA': X_train['MH_CVA'].mean(), 'MH_GIdisorder': X_train['MH_GIdisorder'].mean(), 'MH_CKD': X_train['MH_CKD'].mean(), 'MH_RA': X_train['MH_RA'].mean(), 'Cancer': X_train['Cancer'].mean(), 'MH_HLP': X_train['MH_HLP'].mean(), 'MH_Hep C': X_train['MH_Hep C'].mean(), 'MH_Thyroid dysfunction': X_train['MH_Thyroid dysfunction'].mean(), 'MH_Immunocompromised': X_train['MH_Immunocompromised'].mean(), 'MH_ChronicSeizure': X_train['MH_ChronicSeizure'].mean(), 'MH_TB': X_train['MH_TB'].mean(), 'MH_Anemia': X_train['MH_Anemia'].mean(), 'MH_Fattyliver': X_train['MH_Fattyliver'].mean(), 'MH_Psychologicaldisorder': X_train['MH_Psychologicaldisorder'].mean(), 'MH_Parkinson': X_train['MH_Parkinson'].mean(), 'MH_Alzhimer': X_train['MH_Alzhimer'].mean(), 'symtpm_to_referral': X_train['symtpm_to_referral'].mean(), 'VS_O2satwithoutsupp': X_train['VS_O2satwithoutsupp'].mean(), 'VS_PR': X_train['VS_PR'].mean(), 'VS_diastolic BP': X_train['VS_diastolic BP'].mean(), 'VS_Systolic BP': X_train['VS_Systolic BP'].mean(), 'VS_RR': X_train['VS_RR'].mean(), 'VS_T': X_train['VS_T'].mean(), 'LAB_WBC_1': X_train['LAB_WBC_1'].mean(), 'LAB_LYMPHH_1': X_train['LAB_LYMPHH_1'].mean(), 'LAB_NEUT_1': X_train['LAB_NEUT_1'].mean(), 'LAB_PLT_1': X_train['LAB_PLT_1'].mean(), 'LAB_HB_1': X_train['LAB_HB_1'].mean(), 'LAB_MCV_1': X_train['LAB_MCV_1'].mean(), 'LAB_CR_1': X_train['LAB_CR_1'].mean(), 'LAB_NA_First': X_train['LAB_NA_First'].mean(), 'LAB_K_First': X_train['LAB_K_First'].mean(), 'LAB_ALKP_First': X_train['LAB_ALKP_First'].mean(), 'LAB_ESR_First': X_train['LAB_ESR_First'].mean(), 'LAB_CPK_First': X_train['LAB_CPK_First'].mean(), 'LAB_PTT_First': X_train['LAB_PTT_First'].mean(), 'LAB_PT_First': X_train['LAB_PT_First'].mean(), 'LAB_INR_First': X_train['LAB_INR_First'].mean(), 'Demographic_Age': X_train['Demographic_Age'].mean()})\n",
    "    return X_train\n",
    "\n",
    "X_train = clean_data(X_train.copy())\n",
    "X_test = clean_data(X_test.copy())\n",
    "X_ex = clean_data(X_ex.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# define the function to standard numerca data\n",
    "\n",
    "transform = StandardScaler()\n",
    "\n",
    "def standard(f):\n",
    "    df_ex_normalize = transform.fit_transform(f)\n",
    "    df_ex_normalize = pd.DataFrame(df_ex_normalize)\n",
    "    df_ex_normalize.columns = f.columns\n",
    "    return df_ex_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standarding nmerical data with StandardScaler\n",
    "\n",
    "num = list(X_train.columns[X_train.columns.get_loc('VS_O2satwithoutsupp'): X_train.columns.get_loc('Demographic_Age') + 1]\n",
    ")\n",
    "\n",
    "X_train[num]=standard(X_train[num])\n",
    "X_test[num]=standard(X_test[num])\n",
    "X_ex[num]=standard(X_ex[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# we tried different undersampling and oversampling techniques. SMOTE performed better than others.\n",
    "\n",
    "over_sampler = SMOTE()\n",
    "X_train, y_train = over_sampler.fit_resample(X_train, y_train)\n",
    "X_test, y_test = over_sampler.fit_resample(X_test, y_test)\n",
    "X_ex, y_ex = over_sampler.fit_resample(X_ex, y_ex )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#function that selects most important features using lasso\n",
    "\n",
    "def lasso_feature_selector(X_train, y_train,X_test , X_ex):\n",
    "\n",
    "    \n",
    "    lasso = Lasso(alpha=0.001,random_state=42 )\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    absolute_coeffs = np.abs(lasso.coef_)\n",
    "    sorted_indices = np.argsort(absolute_coeffs)[::-1]\n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_ex = pd.DataFrame(X_ex)\n",
    "\n",
    "    selected_feature_indices = sorted_indices[:40]\n",
    "    selected_feature_indices = np.where(lasso.coef_ != 0)[0]\n",
    "\n",
    "\n",
    "    X_train_selected_Mortality_ICU = X_train.iloc[:, selected_feature_indices]\n",
    "    X_test_selected_Mortality_ICU = X_test.iloc[:, selected_feature_indices]\n",
    "    X_ex = X_ex.iloc[:, selected_feature_indices]\n",
    "    return X_train_selected_Mortality_ICU ,X_test_selected_Mortality_ICU,X_ex, selected_feature_indices\n",
    "\n",
    "X_train,X_test,X_ex, selected_feature_indices = lasso_feature_selector(X_train, y_train,X_test,X_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# metrics caculator function \n",
    "\n",
    "def calculate_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    \n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "\n",
    "def calculate_and_update_model_metrics(y_test, y_predicted,y_ex, y_ex_predicted):\n",
    "    accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_predicted)\n",
    "    model = {}\n",
    "    model[\"accuracy\"] = accuracy\n",
    "    model[\"precision\"] = precision\n",
    "    model[\"recall\"] = recall\n",
    "    model[\"specificity\"] = specificity\n",
    "    model[\"f1\"] = f1\n",
    "    model[\"AUC\"] = roc_auc_score(y_test, y_predicted)\n",
    "    \n",
    "    accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex = calculate_metrics(y_ex, y_ex_predicted)\n",
    "    model[\"accuracy_ex\"] = accuracy_ex\n",
    "    model[\"precision_ex\"] = precision_ex\n",
    "    model[\"recall_ex\"] = recall_ex\n",
    "    model[\"specificity_ex\"] = specificity_ex\n",
    "    model[\"f1_ex\"] = f1_ex\n",
    "    model[\"AUC_ex\"] = roc_auc_score(y_ex, y_ex_predicted)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(X_train, y_train, X_test, y_test, X_ex, y_ex):\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    "    # Predictions and probabilities for test set\n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Predictions and probabilities for external set\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    model_metrics = calculate_and_update_model_metrics(y_test, y_pred_test, y_ex, y_pred_external)\n",
    "\n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "\n",
    "    return model_metrics, y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_svm(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42], 'probability': [True]}\n",
    "    lr = svm.SVC(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_tree(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = DecisionTreeClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_knn(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {}\n",
    "    lr = KNeighborsClassifier()\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_forest(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = RandomForestClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def train_and_evaluate_boost(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_lr = {'random_state':[42]}\n",
    "    lr = XGBClassifier(random_state=42)\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_lr,\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =   calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_neural(X_train, y_train, X_test, y_test , X_ex ,y_ex):\n",
    "\n",
    "    parameters_neural = {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50)],  # You can adjust the architecture here\n",
    "        'activation': ['relu'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.0001],\n",
    "        'max_iter': [200],\n",
    "        'random_state': [42],\n",
    "        'early_stopping': [True],\n",
    "        'validation_fraction': [0.1],\n",
    "        'n_iter_no_change': [10]\n",
    "    }\n",
    "\n",
    "\n",
    "    lr = MLPClassifier(random_state=42)\n",
    "\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        estimator=lr,\n",
    "        param_grid=parameters_neural,\n",
    "        #cv=5\n",
    "    )\n",
    "    \n",
    "    logreg_cv = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    best_classifier_lr = logreg_cv.best_estimator_\n",
    "\n",
    " \n",
    "    y_pred_test = best_classifier_lr.predict(X_test)\n",
    "    y_pred_proba_test = best_classifier_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    y_pred_external = best_classifier_lr.predict(X_ex)\n",
    "    y_pred_proba_external = best_classifier_lr.predict_proba(X_ex)[:, 1]\n",
    "    \n",
    "    Logistic_Regression =  calculate_and_update_model_metrics(y_test, y_pred_test,y_ex, y_pred_external)\n",
    "    \n",
    "    \n",
    "    y_plot = {\n",
    "        \"y_true\": y_test,\n",
    "        \"y_predicted\": y_pred_test,\n",
    "        \"y_true_ex\": y_ex,\n",
    "        \"y_predicted_ex\": y_pred_external,\n",
    "        \"y_pred_proba_test\": y_pred_proba_test,\n",
    "        \"y_pred_proba_external\": y_pred_proba_external\n",
    "    }\n",
    "    \n",
    "    Logistic_Regression = (Logistic_Regression, y_plot)\n",
    "    \n",
    "    return Logistic_Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final function that shows the results of all models in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_models(X_train, y_train, X_test, y_test, X_ex, y_ex):\n",
    "    list_Outcome_InhospitalMortality=[]\n",
    "    y_train_ = np.array(y_train)\n",
    "    y_test_ = np.array(y_test)\n",
    "\n",
    "    y_ex_ = np.array(y_ex)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    list_Outcome_InhospitalMortality.extend([logistic_regression_classifier(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                                train_and_evaluate_svm(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_tree(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_knn(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_forest(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_boost(X_train, y_train_, X_test, y_test_, X_ex ,y_ex_),\n",
    "                                            train_and_evaluate_neural(X_train, y_train, X_test, y_test, X_ex, y_ex)])\n",
    "\n",
    "\n",
    "    result_dic_list_Outcome_InhospitalMortality = dict(zip(['logistic regression', 'SVM', 'Decision tree', 'knn', 'Random forest', 'XGboost', 'neural net'], list_Outcome_InhospitalMortality))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    merged_dict = {}\n",
    "\n",
    "    # List of dictionary names and their corresponding dictionaries\n",
    "    dict_list = [('Outcome_InhospitalMortality', result_dic_list_Outcome_InhospitalMortality)]\n",
    "\n",
    "    # Merge the dictionaries\n",
    "    for name, result_dict in dict_list:\n",
    "        merged_dict[name] = result_dict\n",
    "\n",
    "    # The merged_dict now contains all the dictionaries merged together\n",
    "\n",
    "\n",
    "    dff = pd.DataFrame(merged_dict)\n",
    "\n",
    "\n",
    "    dff = dff.transpose()\n",
    "\n",
    "\n",
    "    dff.reset_index(inplace=True)\n",
    "    dff.rename(columns={'index': 'Method'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for outcome, models in merged_dict.items():\n",
    "        for model, metrics in models.items():\n",
    "            accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex = metrics[0]['accuracy'], metrics[0]['precision'], metrics[0]['recall'], metrics[0]['specificity'], metrics[0]['f1'], metrics[0]['AUC'],metrics[0]['accuracy_ex'], metrics[0]['precision_ex'], metrics[0]['recall_ex'], metrics[0]['specificity_ex'], metrics[0]['f1_ex'], metrics[0]['AUC_ex']\n",
    "            y_true, y_predicted,y_true_ex,y_predicted_ex , y_pred_proba_test , y_pred_proba_external = metrics[1]['y_true'], metrics[1]['y_predicted'],metrics[1]['y_true_ex'], metrics[1]['y_predicted_ex'], metrics[1]['y_pred_proba_test'], metrics[1]['y_pred_proba_external']\n",
    "            data.append([outcome, model,accuracy, precision, recall, specificity, f1, AUC,accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex, AUC_ex, y_true.tolist(), y_predicted.tolist(),y_true_ex.tolist(),y_predicted_ex.tolist(),y_pred_proba_test.tolist(),y_pred_proba_external.tolist()])\n",
    "\n",
    "    columns = ['Outcome', 'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1','AUC', 'Accuracy_ex', 'Precision_ex', 'Recall_ex', 'Specificity_ex', 'F1_ex','AUC_ex', 'y_true', 'y_predicted', 'y_true_ex', 'y_predicted_ex' , 'y_pred_proba_test', 'y_pred_proba_external']\n",
    "\n",
    "    dff = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return dff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the result's table\n",
    "\n",
    "#d = run_all_models(X_train, y_train, X_test, y_test, X_ex, y_ex)\n",
    "\n",
    "#d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train , y_train] , axis=1)\n",
    "train = train.sample(frac=1 , random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demographic_Gender</th>\n",
       "      <th>Symptom_Caugh</th>\n",
       "      <th>Symptom_Dyspnea</th>\n",
       "      <th>Symptom_Fever</th>\n",
       "      <th>Symptom_Chiver</th>\n",
       "      <th>Symptom_Mylagia</th>\n",
       "      <th>Symptom_Weakness</th>\n",
       "      <th>Symptom_LOC</th>\n",
       "      <th>Symptom_Sore through</th>\n",
       "      <th>Symptom_nauseaVomit</th>\n",
       "      <th>...</th>\n",
       "      <th>LAB_NA_First</th>\n",
       "      <th>LAB_K_First</th>\n",
       "      <th>LAB_ALKP_First</th>\n",
       "      <th>LAB_ESR_First</th>\n",
       "      <th>LAB_CPK_First</th>\n",
       "      <th>LAB_PTT_First</th>\n",
       "      <th>LAB_PT_First</th>\n",
       "      <th>LAB_INR_First</th>\n",
       "      <th>Demographic_Age</th>\n",
       "      <th>Outcome_InhospitalMortality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039659</td>\n",
       "      <td>-0.138685</td>\n",
       "      <td>0.417652</td>\n",
       "      <td>-0.761549</td>\n",
       "      <td>-0.200450</td>\n",
       "      <td>-0.135966</td>\n",
       "      <td>-0.260551</td>\n",
       "      <td>-0.136655</td>\n",
       "      <td>1.318845</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>-0.645812</td>\n",
       "      <td>1.950557</td>\n",
       "      <td>-0.266194</td>\n",
       "      <td>-0.024715</td>\n",
       "      <td>-0.027101</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>-0.252738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430458</td>\n",
       "      <td>0.569542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.741374</td>\n",
       "      <td>-0.053881</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>1.321626</td>\n",
       "      <td>-0.413781</td>\n",
       "      <td>-0.047303</td>\n",
       "      <td>0.201971</td>\n",
       "      <td>-0.090277</td>\n",
       "      <td>-0.158664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.036568</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>1.119428</td>\n",
       "      <td>-0.457309</td>\n",
       "      <td>-0.237894</td>\n",
       "      <td>-0.105568</td>\n",
       "      <td>-0.110287</td>\n",
       "      <td>1.016618</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073487</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>0.153524</td>\n",
       "      <td>-0.674062</td>\n",
       "      <td>-0.194334</td>\n",
       "      <td>-0.343742</td>\n",
       "      <td>-0.219766</td>\n",
       "      <td>-0.112106</td>\n",
       "      <td>-0.192292</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>-0.527650</td>\n",
       "      <td>-1.592678</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>-0.299271</td>\n",
       "      <td>-0.045749</td>\n",
       "      <td>-0.057694</td>\n",
       "      <td>0.774836</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594401</td>\n",
       "      <td>-0.016144</td>\n",
       "      <td>0.271686</td>\n",
       "      <td>-1.636422</td>\n",
       "      <td>-0.133178</td>\n",
       "      <td>0.169049</td>\n",
       "      <td>-0.245678</td>\n",
       "      <td>-0.076301</td>\n",
       "      <td>-2.066102</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581424</td>\n",
       "      <td>-0.081154</td>\n",
       "      <td>0.819362</td>\n",
       "      <td>1.035642</td>\n",
       "      <td>0.225183</td>\n",
       "      <td>0.162261</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>-0.092294</td>\n",
       "      <td>-0.554965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.659652</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.135143</td>\n",
       "      <td>-0.390893</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-0.236080</td>\n",
       "      <td>-0.113924</td>\n",
       "      <td>-0.373482</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262288</td>\n",
       "      <td>-0.097838</td>\n",
       "      <td>-0.388635</td>\n",
       "      <td>-0.499087</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>-0.155567</td>\n",
       "      <td>-0.268708</td>\n",
       "      <td>-0.117561</td>\n",
       "      <td>-0.434074</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Demographic_Gender  Symptom_Caugh  Symptom_Dyspnea  Symptom_Fever  \\\n",
       "0              0.000000       0.000000         1.000000       0.000000   \n",
       "1              1.000000       1.000000         0.000000       1.000000   \n",
       "2              0.430458       0.569542         1.000000       0.000000   \n",
       "3              0.000000       1.000000         1.000000       0.000000   \n",
       "4              1.000000       0.000000         0.000000       0.000000   \n",
       "..                  ...            ...              ...            ...   \n",
       "453            1.000000       0.000000         1.000000       0.000000   \n",
       "454            1.000000       0.000000         1.000000       0.000000   \n",
       "455            1.000000       1.000000         1.000000       0.183077   \n",
       "456            0.437651       0.562349         0.562349       1.000000   \n",
       "457            0.000000       0.000000         1.000000       1.000000   \n",
       "\n",
       "     Symptom_Chiver  Symptom_Mylagia  Symptom_Weakness  Symptom_LOC  \\\n",
       "0          0.000000         0.000000          0.000000          0.0   \n",
       "1          1.000000         0.000000          1.000000          0.0   \n",
       "2          0.000000         0.000000          1.000000          0.0   \n",
       "3          0.000000         0.000000          0.000000          0.0   \n",
       "4          0.000000         1.000000          1.000000          0.0   \n",
       "..              ...              ...               ...          ...   \n",
       "453        0.000000         0.000000          0.000000          0.0   \n",
       "454        0.000000         0.000000          1.000000          0.0   \n",
       "455        0.183077         0.816923          0.183077          0.0   \n",
       "456        0.437651         0.437651          0.437651          0.0   \n",
       "457        1.000000         0.000000          0.000000          0.0   \n",
       "\n",
       "     Symptom_Sore through  Symptom_nauseaVomit  ...  LAB_NA_First  \\\n",
       "0                     0.0             0.000000  ...      1.039659   \n",
       "1                     0.0             1.000000  ...      0.371772   \n",
       "2                     0.0             0.000000  ...     -0.741374   \n",
       "3                     0.0             0.000000  ...      0.371772   \n",
       "4                     0.0             0.000000  ...     -0.073487   \n",
       "..                    ...                  ...  ...           ...   \n",
       "453                   0.0             0.000000  ...      0.149142   \n",
       "454                   0.0             1.000000  ...      0.594401   \n",
       "455                   0.0             0.816923  ...     -0.581424   \n",
       "456                   0.0             0.000000  ...     -1.659652   \n",
       "457                   0.0             0.000000  ...      1.262288   \n",
       "\n",
       "     LAB_K_First  LAB_ALKP_First  LAB_ESR_First  LAB_CPK_First  LAB_PTT_First  \\\n",
       "0      -0.138685        0.417652      -0.761549      -0.200450      -0.135966   \n",
       "1      -0.179532       -0.645812       1.950557      -0.266194      -0.024715   \n",
       "2      -0.053881        0.021496       1.321626      -0.413781      -0.047303   \n",
       "3      -0.036568        0.090967       1.119428      -0.457309      -0.237894   \n",
       "4      -0.179532        0.153524      -0.674062      -0.194334      -0.343742   \n",
       "..           ...             ...            ...            ...            ...   \n",
       "453    -0.179532       -0.527650      -1.592678       0.004425      -0.299271   \n",
       "454    -0.016144        0.271686      -1.636422      -0.133178       0.169049   \n",
       "455    -0.081154        0.819362       1.035642       0.225183       0.162261   \n",
       "456    -0.125902        0.747855       0.135143      -0.390893       0.003746   \n",
       "457    -0.097838       -0.388635      -0.499087       0.028176      -0.155567   \n",
       "\n",
       "     LAB_PT_First  LAB_INR_First  Demographic_Age  Outcome_InhospitalMortality  \n",
       "0       -0.260551      -0.136655         1.318845                          0.0  \n",
       "1       -0.027101       0.003112        -0.252738                          1.0  \n",
       "2        0.201971      -0.090277        -0.158664                          0.0  \n",
       "3       -0.105568      -0.110287         1.016618                          1.0  \n",
       "4       -0.219766      -0.112106        -0.192292                          1.0  \n",
       "..            ...            ...              ...                          ...  \n",
       "453     -0.045749      -0.057694         0.774836                          1.0  \n",
       "454     -0.245678      -0.076301        -2.066102                          0.0  \n",
       "455     -0.035368      -0.092294        -0.554965                          0.0  \n",
       "456     -0.236080      -0.113924        -0.373482                          0.0  \n",
       "457     -0.268708      -0.117561        -0.434074                          1.0  \n",
       "\n",
       "[458 rows x 56 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Outcome_InhospitalMortality']\n",
    "X_train = train.drop('Outcome_InhospitalMortality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Demographic_Gender</th>\n",
       "      <th>Symptom_Caugh</th>\n",
       "      <th>Symptom_Dyspnea</th>\n",
       "      <th>Symptom_Fever</th>\n",
       "      <th>Symptom_Chiver</th>\n",
       "      <th>Symptom_Mylagia</th>\n",
       "      <th>Symptom_Weakness</th>\n",
       "      <th>Symptom_LOC</th>\n",
       "      <th>Symptom_Sore through</th>\n",
       "      <th>Symptom_nauseaVomit</th>\n",
       "      <th>...</th>\n",
       "      <th>LAB_CR_1</th>\n",
       "      <th>LAB_NA_First</th>\n",
       "      <th>LAB_K_First</th>\n",
       "      <th>LAB_ALKP_First</th>\n",
       "      <th>LAB_ESR_First</th>\n",
       "      <th>LAB_CPK_First</th>\n",
       "      <th>LAB_PTT_First</th>\n",
       "      <th>LAB_PT_First</th>\n",
       "      <th>LAB_INR_First</th>\n",
       "      <th>Demographic_Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003263</td>\n",
       "      <td>1.039659</td>\n",
       "      <td>-0.138685</td>\n",
       "      <td>0.417652</td>\n",
       "      <td>-0.761549</td>\n",
       "      <td>-0.200450</td>\n",
       "      <td>-0.135966</td>\n",
       "      <td>-0.260551</td>\n",
       "      <td>-0.136655</td>\n",
       "      <td>1.318845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456227</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>-0.645812</td>\n",
       "      <td>1.950557</td>\n",
       "      <td>-0.266194</td>\n",
       "      <td>-0.024715</td>\n",
       "      <td>-0.027101</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>-0.252738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430458</td>\n",
       "      <td>0.569542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015608</td>\n",
       "      <td>-0.741374</td>\n",
       "      <td>-0.053881</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>1.321626</td>\n",
       "      <td>-0.413781</td>\n",
       "      <td>-0.047303</td>\n",
       "      <td>0.201971</td>\n",
       "      <td>-0.090277</td>\n",
       "      <td>-0.158664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207763</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.036568</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>1.119428</td>\n",
       "      <td>-0.457309</td>\n",
       "      <td>-0.237894</td>\n",
       "      <td>-0.105568</td>\n",
       "      <td>-0.110287</td>\n",
       "      <td>1.016618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132346</td>\n",
       "      <td>-0.073487</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>0.153524</td>\n",
       "      <td>-0.674062</td>\n",
       "      <td>-0.194334</td>\n",
       "      <td>-0.343742</td>\n",
       "      <td>-0.219766</td>\n",
       "      <td>-0.112106</td>\n",
       "      <td>-0.192292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197122</td>\n",
       "      <td>0.149142</td>\n",
       "      <td>-0.179532</td>\n",
       "      <td>-0.527650</td>\n",
       "      <td>-1.592678</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>-0.299271</td>\n",
       "      <td>-0.045749</td>\n",
       "      <td>-0.057694</td>\n",
       "      <td>0.774836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>0.594401</td>\n",
       "      <td>-0.016144</td>\n",
       "      <td>0.271686</td>\n",
       "      <td>-1.636422</td>\n",
       "      <td>-0.133178</td>\n",
       "      <td>0.169049</td>\n",
       "      <td>-0.245678</td>\n",
       "      <td>-0.076301</td>\n",
       "      <td>-2.066102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>0.183077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261898</td>\n",
       "      <td>-0.581424</td>\n",
       "      <td>-0.081154</td>\n",
       "      <td>0.819362</td>\n",
       "      <td>1.035642</td>\n",
       "      <td>0.225183</td>\n",
       "      <td>0.162261</td>\n",
       "      <td>-0.035368</td>\n",
       "      <td>-0.092294</td>\n",
       "      <td>-0.554965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>0.562349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.437651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220727</td>\n",
       "      <td>-1.659652</td>\n",
       "      <td>-0.125902</td>\n",
       "      <td>0.747855</td>\n",
       "      <td>0.135143</td>\n",
       "      <td>-0.390893</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-0.236080</td>\n",
       "      <td>-0.113924</td>\n",
       "      <td>-0.373482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197122</td>\n",
       "      <td>1.262288</td>\n",
       "      <td>-0.097838</td>\n",
       "      <td>-0.388635</td>\n",
       "      <td>-0.499087</td>\n",
       "      <td>0.028176</td>\n",
       "      <td>-0.155567</td>\n",
       "      <td>-0.268708</td>\n",
       "      <td>-0.117561</td>\n",
       "      <td>-0.434074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Demographic_Gender  Symptom_Caugh  Symptom_Dyspnea  Symptom_Fever  \\\n",
       "0              0.000000       0.000000         1.000000       0.000000   \n",
       "1              1.000000       1.000000         0.000000       1.000000   \n",
       "2              0.430458       0.569542         1.000000       0.000000   \n",
       "3              0.000000       1.000000         1.000000       0.000000   \n",
       "4              1.000000       0.000000         0.000000       0.000000   \n",
       "..                  ...            ...              ...            ...   \n",
       "453            1.000000       0.000000         1.000000       0.000000   \n",
       "454            1.000000       0.000000         1.000000       0.000000   \n",
       "455            1.000000       1.000000         1.000000       0.183077   \n",
       "456            0.437651       0.562349         0.562349       1.000000   \n",
       "457            0.000000       0.000000         1.000000       1.000000   \n",
       "\n",
       "     Symptom_Chiver  Symptom_Mylagia  Symptom_Weakness  Symptom_LOC  \\\n",
       "0          0.000000         0.000000          0.000000          0.0   \n",
       "1          1.000000         0.000000          1.000000          0.0   \n",
       "2          0.000000         0.000000          1.000000          0.0   \n",
       "3          0.000000         0.000000          0.000000          0.0   \n",
       "4          0.000000         1.000000          1.000000          0.0   \n",
       "..              ...              ...               ...          ...   \n",
       "453        0.000000         0.000000          0.000000          0.0   \n",
       "454        0.000000         0.000000          1.000000          0.0   \n",
       "455        0.183077         0.816923          0.183077          0.0   \n",
       "456        0.437651         0.437651          0.437651          0.0   \n",
       "457        1.000000         0.000000          0.000000          0.0   \n",
       "\n",
       "     Symptom_Sore through  Symptom_nauseaVomit  ...  LAB_CR_1  LAB_NA_First  \\\n",
       "0                     0.0             0.000000  ... -0.003263      1.039659   \n",
       "1                     0.0             1.000000  ... -0.456227      0.371772   \n",
       "2                     0.0             0.000000  ... -0.015608     -0.741374   \n",
       "3                     0.0             0.000000  ...  0.207763      0.371772   \n",
       "4                     0.0             0.000000  ... -0.132346     -0.073487   \n",
       "..                    ...                  ...  ...       ...           ...   \n",
       "453                   0.0             0.000000  ... -0.197122      0.149142   \n",
       "454                   0.0             1.000000  ... -0.002793      0.594401   \n",
       "455                   0.0             0.816923  ... -0.261898     -0.581424   \n",
       "456                   0.0             0.000000  ... -0.220727     -1.659652   \n",
       "457                   0.0             0.000000  ... -0.197122      1.262288   \n",
       "\n",
       "     LAB_K_First  LAB_ALKP_First  LAB_ESR_First  LAB_CPK_First  LAB_PTT_First  \\\n",
       "0      -0.138685        0.417652      -0.761549      -0.200450      -0.135966   \n",
       "1      -0.179532       -0.645812       1.950557      -0.266194      -0.024715   \n",
       "2      -0.053881        0.021496       1.321626      -0.413781      -0.047303   \n",
       "3      -0.036568        0.090967       1.119428      -0.457309      -0.237894   \n",
       "4      -0.179532        0.153524      -0.674062      -0.194334      -0.343742   \n",
       "..           ...             ...            ...            ...            ...   \n",
       "453    -0.179532       -0.527650      -1.592678       0.004425      -0.299271   \n",
       "454    -0.016144        0.271686      -1.636422      -0.133178       0.169049   \n",
       "455    -0.081154        0.819362       1.035642       0.225183       0.162261   \n",
       "456    -0.125902        0.747855       0.135143      -0.390893       0.003746   \n",
       "457    -0.097838       -0.388635      -0.499087       0.028176      -0.155567   \n",
       "\n",
       "     LAB_PT_First  LAB_INR_First  Demographic_Age  \n",
       "0       -0.260551      -0.136655         1.318845  \n",
       "1       -0.027101       0.003112        -0.252738  \n",
       "2        0.201971      -0.090277        -0.158664  \n",
       "3       -0.105568      -0.110287         1.016618  \n",
       "4       -0.219766      -0.112106        -0.192292  \n",
       "..            ...            ...              ...  \n",
       "453     -0.045749      -0.057694         0.774836  \n",
       "454     -0.245678      -0.076301        -2.066102  \n",
       "455     -0.035368      -0.092294        -0.554965  \n",
       "456     -0.236080      -0.113924        -0.373482  \n",
       "457     -0.268708      -0.117561        -0.434074  \n",
       "\n",
       "[458 rows x 55 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_ex</th>\n",
       "      <th>Precision_ex</th>\n",
       "      <th>Recall_ex</th>\n",
       "      <th>Specificity_ex</th>\n",
       "      <th>F1_ex</th>\n",
       "      <th>AUC_ex</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predicted</th>\n",
       "      <th>y_true_ex</th>\n",
       "      <th>y_predicted_ex</th>\n",
       "      <th>y_pred_proba_test</th>\n",
       "      <th>y_pred_proba_external</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>logistic regression</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.684609</td>\n",
       "      <td>0.698185</td>\n",
       "      <td>0.650356</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>0.673422</td>\n",
       "      <td>0.684609</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.47889362695141924, 0.9851107476847817, 0.03...</td>\n",
       "      <td>[0.16871484679598914, 0.7344214092663468, 0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.673932</td>\n",
       "      <td>0.692232</td>\n",
       "      <td>0.626335</td>\n",
       "      <td>0.721530</td>\n",
       "      <td>0.657637</td>\n",
       "      <td>0.673932</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.67064561261288, 0.8731227321007632, 0.28933...</td>\n",
       "      <td>[0.22421358268690836, 0.7403308637106965, 0.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.631228</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.637900</td>\n",
       "      <td>0.624555</td>\n",
       "      <td>0.633672</td>\n",
       "      <td>0.631228</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>knn</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.657568</td>\n",
       "      <td>0.471530</td>\n",
       "      <td>0.754448</td>\n",
       "      <td>0.549223</td>\n",
       "      <td>0.612989</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.2, 1.0, 0.2, 0.4, 0.0, 0.4, 0.6, 0.4, 1.0, ...</td>\n",
       "      <td>[0.2, 0.6, 0.2, 0.8, 0.6, 0.2, 0.2, 0.0, 0.2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.728203</td>\n",
       "      <td>0.742210</td>\n",
       "      <td>0.699288</td>\n",
       "      <td>0.757117</td>\n",
       "      <td>0.720110</td>\n",
       "      <td>0.728203</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.43, 0.71, 0.29, 0.57, 0.36, 0.58, 0.87, 0.4...</td>\n",
       "      <td>[0.24, 0.38, 0.34, 0.68, 0.48, 0.48, 0.5, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.717527</td>\n",
       "      <td>0.729147</td>\n",
       "      <td>0.692171</td>\n",
       "      <td>0.742883</td>\n",
       "      <td>0.710178</td>\n",
       "      <td>0.717527</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.7562947273254395, 0.9646049737930298, 0.003...</td>\n",
       "      <td>[0.005193131044507027, 0.2094302922487259, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Outcome_InhospitalMortality</td>\n",
       "      <td>neural net</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.669929</td>\n",
       "      <td>0.663808</td>\n",
       "      <td>0.688612</td>\n",
       "      <td>0.651246</td>\n",
       "      <td>0.675983</td>\n",
       "      <td>0.669929</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5747518305833115, 0.8424115951060581, 0.203...</td>\n",
       "      <td>[0.4753492093818341, 0.6443073727909695, 0.477...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Outcome                Model  Accuracy  Precision  \\\n",
       "0  Outcome_InhospitalMortality  logistic regression  0.690909   0.677966   \n",
       "1  Outcome_InhospitalMortality                  SVM  0.681818   0.672414   \n",
       "2  Outcome_InhospitalMortality        Decision tree  0.636364   0.636364   \n",
       "3  Outcome_InhospitalMortality                  knn  0.618182   0.651163   \n",
       "4  Outcome_InhospitalMortality        Random forest  0.709091   0.701754   \n",
       "5  Outcome_InhospitalMortality              XGboost  0.763636   0.763636   \n",
       "6  Outcome_InhospitalMortality           neural net  0.690909   0.677966   \n",
       "\n",
       "     Recall  Specificity        F1       AUC  Accuracy_ex  Precision_ex  \\\n",
       "0  0.727273     0.654545  0.701754  0.690909     0.684609      0.698185   \n",
       "1  0.709091     0.654545  0.690265  0.681818     0.673932      0.692232   \n",
       "2  0.636364     0.636364  0.636364  0.636364     0.631228      0.629500   \n",
       "3  0.509091     0.727273  0.571429  0.618182     0.612989      0.657568   \n",
       "4  0.727273     0.690909  0.714286  0.709091     0.728203      0.742210   \n",
       "5  0.763636     0.763636  0.763636  0.763636     0.717527      0.729147   \n",
       "6  0.727273     0.654545  0.701754  0.690909     0.669929      0.663808   \n",
       "\n",
       "   Recall_ex  Specificity_ex     F1_ex    AUC_ex  \\\n",
       "0   0.650356        0.718861  0.673422  0.684609   \n",
       "1   0.626335        0.721530  0.657637  0.673932   \n",
       "2   0.637900        0.624555  0.633672  0.631228   \n",
       "3   0.471530        0.754448  0.549223  0.612989   \n",
       "4   0.699288        0.757117  0.720110  0.728203   \n",
       "5   0.692171        0.742883  0.710178  0.717527   \n",
       "6   0.688612        0.651246  0.675983  0.669929   \n",
       "\n",
       "                                              y_true  \\\n",
       "0  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                         y_predicted  \\\n",
       "0  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...   \n",
       "2  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...   \n",
       "4  [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...   \n",
       "5  [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, ...   \n",
       "6  [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, ...   \n",
       "\n",
       "                                           y_true_ex  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "5  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "6  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "\n",
       "                                      y_predicted_ex  \\\n",
       "0  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "1  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "3  [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n",
       "5  [0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, ...   \n",
       "6  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                   y_pred_proba_test  \\\n",
       "0  [0.47889362695141924, 0.9851107476847817, 0.03...   \n",
       "1  [0.67064561261288, 0.8731227321007632, 0.28933...   \n",
       "2  [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [0.2, 1.0, 0.2, 0.4, 0.0, 0.4, 0.6, 0.4, 1.0, ...   \n",
       "4  [0.43, 0.71, 0.29, 0.57, 0.36, 0.58, 0.87, 0.4...   \n",
       "5  [0.7562947273254395, 0.9646049737930298, 0.003...   \n",
       "6  [0.5747518305833115, 0.8424115951060581, 0.203...   \n",
       "\n",
       "                               y_pred_proba_external  \n",
       "0  [0.16871484679598914, 0.7344214092663468, 0.16...  \n",
       "1  [0.22421358268690836, 0.7403308637106965, 0.34...  \n",
       "2  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n",
       "3  [0.2, 0.6, 0.2, 0.8, 0.6, 0.2, 0.2, 0.0, 0.2, ...  \n",
       "4  [0.24, 0.38, 0.34, 0.68, 0.48, 0.48, 0.5, 0.45...  \n",
       "5  [0.005193131044507027, 0.2094302922487259, 0.0...  \n",
       "6  [0.4753492093818341, 0.6443073727909695, 0.477...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_Q = X_train\n",
    "y_train_Q = y_train\n",
    "d = run_all_models(X_train_Q, y_train_Q, X_test, y_test, X_ex, y_ex)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"samples = [20 , 100 , 200 , 400 , 1000 ]\\n\\nfor sample in samples :\\n    X_train_Q = X_train[: sample]\\n    y_train_Q = y_train[: sample]\\n    d = run_all_models(X_train_Q, y_train_Q, X_test, y_test, X_ex, y_ex)\\n    d.to_csv(f'CML_{sample}.csv',index=False)\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''samples = [20 , 100 , 200 , 400 , 1000 ]\n",
    "\n",
    "for sample in samples :\n",
    "    X_train_Q = X_train[: sample]\n",
    "    y_train_Q = y_train[: sample]\n",
    "    d = run_all_models(X_train_Q, y_train_Q, X_test, y_test, X_ex, y_ex)\n",
    "    d.to_csv(f'CML_{sample}.csv',index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#d= run_all_models(X_train, y_train, X_test, y_test, X_ex, y_ex)\n",
    "#d.to_csv(f'CML_{10}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.to_csv('CML_prob.csv',index=False)\n",
    "#d.to_excel('CML_prob.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
