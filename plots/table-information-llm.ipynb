{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_external = pd.read_csv('4epochs_mistral_external_test_predictions.csv')\n",
    "llm_internal = pd.read_csv('4epochs_mistral_internaltest_predictions.csv')\n",
    "zer_in = pd.read_csv('mstral_zero_predictions.csv')\n",
    "zer_ex = pd.read_csv('test_external_zero_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_external.replace('die',0 , inplace=True)\n",
    "llm_external.replace('survive',1 , inplace=True)\n",
    "\n",
    "llm_internal.replace('die',0 , inplace=True)\n",
    "llm_internal.replace('survive',1 , inplace=True)\n",
    "\n",
    "zer_in.replace('die',0 , inplace=True)\n",
    "zer_in.replace('survive',1 , inplace=True)\n",
    "\n",
    "zer_ex.replace('die',0 , inplace=True)\n",
    "zer_ex.replace('survive',1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# metrics caculator function \n",
    "\n",
    "def calculate_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted)\n",
    "    recall = recall_score(y_test, y_predicted)\n",
    "    specificity = cm[0, 0] / (cm[0, 0] + cm[0, 1]) if (cm[0, 0] + cm[0, 1]) != 0 else 0\n",
    "    f1 = f1_score(y_test, y_predicted)\n",
    "    \n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "\n",
    "def calculate_and_update_model_metrics(y_test, y_predicted,y_ex, y_ex_predicted):\n",
    "    accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_predicted)\n",
    "    model = {}\n",
    "    model[\"accuracy\"] = accuracy\n",
    "    model[\"precision\"] = precision\n",
    "    model[\"recall\"] = recall\n",
    "    model[\"specificity\"] = specificity\n",
    "    model[\"f1\"] = f1\n",
    "    model[\"AUC\"] = roc_auc_score(y_test, y_predicted)\n",
    "    \n",
    "    accuracy_ex, precision_ex, recall_ex, specificity_ex, f1_ex = calculate_metrics(y_ex, y_ex_predicted)\n",
    "    model[\"accuracy_ex\"] = accuracy_ex\n",
    "    model[\"precision_ex\"] = precision_ex\n",
    "    model[\"recall_ex\"] = recall_ex\n",
    "    model[\"specificity_ex\"] = specificity_ex\n",
    "    model[\"f1_ex\"] = f1_ex\n",
    "    model[\"AUC_ex\"] = roc_auc_score(y_ex, y_ex_predicted)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = calculate_and_update_model_metrics(llm_internal['y_true'].tolist(), llm_internal['y_pred'].tolist(),llm_external['y_true'].tolist(), llm_external['y_pred'].tolist())\n",
    "df = pd.DataFrame(data , index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = calculate_and_update_model_metrics(zer_in['y_true'].tolist(), zer_in['y_pred'].tolist(),zer_ex['y_true'].tolist(), zer_ex['y_pred'].tolist())\n",
    "df2 = pd.DataFrame(data , index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat([df , df2] ,axis= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_excel('fine_tuned-and-zero_shot.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
